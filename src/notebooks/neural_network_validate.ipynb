{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" neural network \"\"\"\n",
    "# importing packages\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from pickle import dump, load\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "z         0.479000\n",
       "M_i     -24.046000\n",
       "ug        0.238531\n",
       "gr       -0.050367\n",
       "ri        0.082918\n",
       "iz        0.077531\n",
       "zu       -0.348612\n",
       "tau       2.227110\n",
       "sigma    -0.660666\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize data\n",
    "df = pd.read_csv('../../data/TRAIN.csv')\n",
    "df2 = pd.read_csv('/Users/SnehPandya/Desktop/nn/train_drw_full.csv')\n",
    "df.iloc[1,14:23]\n",
    "df2.iloc[1,14:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Black Hole dataset--default parameters are for training and predicting AGN mass.  Pass 'train=False' \n",
    "# for test-set and 'mass=False' for AGN redshift prediction.\n",
    "class BHDataset(Dataset):\n",
    "    def __init__(self, path, train=True, mass=True):\n",
    "        self.path = path\n",
    "        self.train = train\n",
    "        self.mass = mass\n",
    "        self.sc = StandardScaler()\n",
    "        \n",
    "        if self.mass:\n",
    "            \n",
    "            if self.train:\n",
    "                self.data = pd.read_csv(self.path + 'TRAIN.csv')\n",
    "                self.features = self.sc.fit_transform(np.asarray(self.data.iloc[:,14:23]))\n",
    "                dump(self.sc, open('train_scaler_drw_full.pkl','wb'))\n",
    "        \n",
    "            else:\n",
    "                self.data = pd.read_csv(self.path + 'TEST.csv')\n",
    "                self.sc = load(open('train_scaler_drw_full.pkl','rb'))\n",
    "                self.features = self.sc.transform(np.asarray(self.data.iloc[:,14:23]))\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            if self.train:\n",
    "                self.data = pd.read_csv(self.path + 'TRAIN.csv')\n",
    "                self.features = self.sc.fit_transform(np.asarray(self.data.iloc[:,[9,10,11,12,13,16,17,18,19,20]]))\n",
    "                dump(self.sc, open('train_scaler_drw_full.pkl','wb'))\n",
    "        \n",
    "            else:\n",
    "                self.data = pd.read_csv(self.path + 'TEST.csv')\n",
    "                self.sc = load(open('train_scaler_drw_full.pkl','rb'))\n",
    "                self.features = self.sc.transform(np.asarray(self.data.iloc[:,[9,10,11,12,13,16,17,18,19,20]]))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.mass:\n",
    "            \n",
    "            ID = torch.from_numpy(np.asarray(self.data.iloc[index,0]))\n",
    "            target = torch.from_numpy(np.asarray(self.data.iloc[index,1]))\n",
    "            features = torch.from_numpy(self.features[index].reshape(1,-1).squeeze())\n",
    "            return (ID, features, target)\n",
    "        \n",
    "        else:\n",
    "            ID = torch.from_numpy(np.asarray(self.data.iloc[index,0]))\n",
    "            target = torch.from_numpy(np.asarray(self.data.iloc[index,14]))\n",
    "            features = torch.from_numpy(self.features[index].reshape(1,-1).squeeze())\n",
    "            return (ID, features, target)\n",
    "\n",
    "        \n",
    "# define train and test datasets.  Train test split was done previously using sklearn.\n",
    "train_mass = BHDataset('../../data/')\n",
    "test_mass = BHDataset('../../data/', train=False)\n",
    "\n",
    "train_z = BHDataset('../../data/', mass=False)\n",
    "test_z = BHDataset('../../data/', mass=False, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloaders with the datasets.  Only shuffle training sets.\n",
    "train_dl_mass = DataLoader(train_mass, batch_size=100, shuffle=True)\n",
    "test_dl_mass = DataLoader(test_mass, batch_size=100, shuffle=False)\n",
    "\n",
    "train_dl_z = DataLoader(train_z, batch_size=100, shuffle=True)\n",
    "test_dl_z = DataLoader(test_z, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default architecture is to predict AGN mass.  Pass 'mass=False' to predict redshift.\n",
    "class AGNet(nn.Module):\n",
    "    def __init__(self, mass=True):\n",
    "        super().__init__()\n",
    "        self.mass = mass\n",
    "        \n",
    "        if self.mass:\n",
    "\n",
    "            self.fc1 = nn.Linear(9, 32)\n",
    "            self.fc2 = nn.Linear(32, 64)\n",
    "            self.fc3 = nn.Linear(64, 64)\n",
    "            self.fc4 = nn.Linear(64, 32)\n",
    "            self.fc5 = nn.Linear(32, 1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.fc1 = nn.Linear(10, 32)\n",
    "            self.fc2 = nn.Linear(32, 64)\n",
    "            self.fc3 = nn.Linear(64, 64)\n",
    "            self.fc4 = nn.Linear(64, 32)\n",
    "            self.fc5 = nn.Linear(32, 1)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "# defining neural networks\n",
    "net_mass = AGNet()\n",
    "net_z = AGNet(mass=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8705, 8737)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count parameters for reference.  For both redshift and mass, (training size/model parameters) < 1.\n",
    "(count_parameters(net_mass), count_parameters(net_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer -- change argument of optimizer to correct network depending on prediction\n",
    "lr = .01\n",
    "optimizer = optim.AdamW(net_mass.parameters(), lr=lr)\n",
    "loss_function = F.smooth_l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop takes in epoch #, network, train loader, loss function, and optimizer.  \n",
    "# Plots RMSE pr epoch and returns RMSE/loss vs. epoch plots at end\n",
    "def train(num_epochs, trainloader, testloader, mdl):\n",
    "    \n",
    "    epoch_list = np.linspace(1, num_epochs , num = num_epochs)\n",
    "    loss_list, rmse_list = list(), list()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "            train_pred, train_gt, test_pred, test_gt = list(), list(), list(), list()\n",
    "\n",
    "            for data in trainloader:\n",
    "\n",
    "                ID, features, ground_truth = data\n",
    "                train_gt.append(ground_truth.float())\n",
    "                output_train = mdl(features.float())\n",
    "                train_pred.append(output_train.float())\n",
    "                train_loss = loss_function(output_train.squeeze(), ground_truth.float().squeeze())\n",
    "                mdl.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_ground_truth = torch.cat(train_gt).data\n",
    "            train_predictions = torch.cat(train_pred).data.flatten()\n",
    "            train_rmse = np.sqrt(metrics.mean_squared_error(train_ground_truth, train_predictions))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data_ in testloader:  \n",
    "\n",
    "                    ID_, features_, ground_truth_ = data_  \n",
    "                    test_gt.append(ground_truth_.float())\n",
    "                    output_test = mdl(features_.float()) \n",
    "                    test_pred.append(output_test.float())\n",
    "                    test_loss = loss_function(output_test.squeeze(), ground_truth_.float())\n",
    "                    test_rmse = np.sqrt(metrics.mean_squared_error(output_test.squeeze().detach().numpy(), ground_truth_.float().squeeze().detach().numpy()))\n",
    "\n",
    "                test_ground_truth = torch.cat(test_gt).data\n",
    "                test_predictions = torch.cat(test_pred).data.flatten()\n",
    "                test_rmse = np.sqrt(metrics.mean_squared_error(test_ground_truth, test_predictions))\n",
    "\n",
    "                print(f'EPOCH: {epoch+1}\\nTrain Loss: {train_loss.item():.5f} | Train RMSE: {train_rmse:.5f}\\nTest Loss: {test_loss.item():.5f} | Test RMSE: {test_rmse:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "Train Loss: 0.11561 | Train RMSE: 2.71970\n",
      "Test Loss: 0.08652 | Test RMSE: 0.47074\n",
      "EPOCH: 2\n",
      "Train Loss: 0.07911 | Train RMSE: 0.45523\n",
      "Test Loss: 0.06912 | Test RMSE: 0.43378\n",
      "EPOCH: 3\n",
      "Train Loss: 0.08644 | Train RMSE: 0.42195\n",
      "Test Loss: 0.06493 | Test RMSE: 0.39172\n",
      "EPOCH: 4\n",
      "Train Loss: 0.09880 | Train RMSE: 0.41829\n",
      "Test Loss: 0.07936 | Test RMSE: 0.41992\n",
      "EPOCH: 5\n",
      "Train Loss: 0.11981 | Train RMSE: 0.43280\n",
      "Test Loss: 0.07290 | Test RMSE: 0.41174\n",
      "EPOCH: 6\n",
      "Train Loss: 0.07620 | Train RMSE: 0.40724\n",
      "Test Loss: 0.07111 | Test RMSE: 0.40638\n",
      "EPOCH: 7\n",
      "Train Loss: 0.07872 | Train RMSE: 0.41075\n",
      "Test Loss: 0.05296 | Test RMSE: 0.37471\n",
      "EPOCH: 8\n",
      "Train Loss: 0.06451 | Train RMSE: 0.40895\n",
      "Test Loss: 0.08424 | Test RMSE: 0.46292\n",
      "EPOCH: 9\n",
      "Train Loss: 0.12743 | Train RMSE: 0.40797\n",
      "Test Loss: 0.09759 | Test RMSE: 0.48624\n",
      "EPOCH: 10\n",
      "Train Loss: 0.15242 | Train RMSE: 0.43338\n",
      "Test Loss: 0.09600 | Test RMSE: 0.45413\n",
      "EPOCH: 11\n",
      "Train Loss: 0.10797 | Train RMSE: 0.41379\n",
      "Test Loss: 0.06112 | Test RMSE: 0.38156\n",
      "EPOCH: 12\n",
      "Train Loss: 0.04898 | Train RMSE: 0.40622\n",
      "Test Loss: 0.05373 | Test RMSE: 0.36232\n",
      "EPOCH: 13\n",
      "Train Loss: 0.07291 | Train RMSE: 0.40420\n",
      "Test Loss: 0.06507 | Test RMSE: 0.41205\n",
      "EPOCH: 14\n",
      "Train Loss: 0.05970 | Train RMSE: 0.38471\n",
      "Test Loss: 0.04705 | Test RMSE: 0.37337\n",
      "EPOCH: 15\n",
      "Train Loss: 0.12724 | Train RMSE: 0.40746\n",
      "Test Loss: 0.05609 | Test RMSE: 0.37516\n",
      "EPOCH: 16\n",
      "Train Loss: 0.09498 | Train RMSE: 0.39503\n",
      "Test Loss: 0.08543 | Test RMSE: 0.43470\n",
      "EPOCH: 17\n",
      "Train Loss: 0.08730 | Train RMSE: 0.38915\n",
      "Test Loss: 0.07011 | Test RMSE: 0.41410\n",
      "EPOCH: 18\n",
      "Train Loss: 0.08197 | Train RMSE: 0.37472\n",
      "Test Loss: 0.05271 | Test RMSE: 0.37206\n",
      "EPOCH: 19\n",
      "Train Loss: 0.06760 | Train RMSE: 0.39330\n",
      "Test Loss: 0.05141 | Test RMSE: 0.36545\n",
      "EPOCH: 20\n",
      "Train Loss: 0.10840 | Train RMSE: 0.37480\n",
      "Test Loss: 0.04942 | Test RMSE: 0.36366\n",
      "EPOCH: 21\n",
      "Train Loss: 0.06904 | Train RMSE: 0.37068\n",
      "Test Loss: 0.05120 | Test RMSE: 0.36066\n",
      "EPOCH: 22\n",
      "Train Loss: 0.06157 | Train RMSE: 0.37292\n",
      "Test Loss: 0.05024 | Test RMSE: 0.36299\n",
      "EPOCH: 23\n",
      "Train Loss: 0.09782 | Train RMSE: 0.37153\n",
      "Test Loss: 0.11153 | Test RMSE: 0.49088\n",
      "EPOCH: 24\n",
      "Train Loss: 0.06035 | Train RMSE: 0.38880\n",
      "Test Loss: 0.05483 | Test RMSE: 0.38733\n",
      "EPOCH: 25\n",
      "Train Loss: 0.08087 | Train RMSE: 0.36975\n",
      "Test Loss: 0.05103 | Test RMSE: 0.36048\n",
      "EPOCH: 26\n",
      "Train Loss: 0.05119 | Train RMSE: 0.37905\n",
      "Test Loss: 0.05412 | Test RMSE: 0.37157\n",
      "EPOCH: 27\n",
      "Train Loss: 0.09607 | Train RMSE: 0.37569\n",
      "Test Loss: 0.06101 | Test RMSE: 0.39058\n",
      "EPOCH: 28\n",
      "Train Loss: 0.10045 | Train RMSE: 0.39454\n",
      "Test Loss: 0.05744 | Test RMSE: 0.37475\n",
      "EPOCH: 29\n",
      "Train Loss: 0.07440 | Train RMSE: 0.38005\n",
      "Test Loss: 0.05017 | Test RMSE: 0.36483\n",
      "EPOCH: 30\n",
      "Train Loss: 0.05376 | Train RMSE: 0.38271\n",
      "Test Loss: 0.04932 | Test RMSE: 0.35777\n",
      "EPOCH: 31\n",
      "Train Loss: 0.07646 | Train RMSE: 0.37802\n",
      "Test Loss: 0.07013 | Test RMSE: 0.40665\n",
      "EPOCH: 32\n",
      "Train Loss: 0.07298 | Train RMSE: 0.38715\n",
      "Test Loss: 0.05512 | Test RMSE: 0.36985\n",
      "EPOCH: 33\n",
      "Train Loss: 0.07040 | Train RMSE: 0.38789\n",
      "Test Loss: 0.05181 | Test RMSE: 0.36456\n",
      "EPOCH: 34\n",
      "Train Loss: 0.09552 | Train RMSE: 0.38021\n",
      "Test Loss: 0.05099 | Test RMSE: 0.36883\n",
      "EPOCH: 35\n",
      "Train Loss: 0.07082 | Train RMSE: 0.37797\n",
      "Test Loss: 0.05117 | Test RMSE: 0.36849\n",
      "EPOCH: 36\n",
      "Train Loss: 0.08158 | Train RMSE: 0.40675\n",
      "Test Loss: 0.05247 | Test RMSE: 0.36413\n",
      "EPOCH: 37\n",
      "Train Loss: 0.08588 | Train RMSE: 0.39708\n",
      "Test Loss: 0.05138 | Test RMSE: 0.37061\n",
      "EPOCH: 38\n",
      "Train Loss: 0.06708 | Train RMSE: 0.36779\n",
      "Test Loss: 0.05899 | Test RMSE: 0.39100\n",
      "EPOCH: 39\n",
      "Train Loss: 0.04878 | Train RMSE: 0.37365\n",
      "Test Loss: 0.05256 | Test RMSE: 0.37087\n",
      "EPOCH: 40\n",
      "Train Loss: 0.06447 | Train RMSE: 0.36826\n",
      "Test Loss: 0.08698 | Test RMSE: 0.45662\n",
      "EPOCH: 41\n",
      "Train Loss: 0.06282 | Train RMSE: 0.37757\n",
      "Test Loss: 0.05615 | Test RMSE: 0.37286\n",
      "EPOCH: 42\n",
      "Train Loss: 0.07997 | Train RMSE: 0.37158\n",
      "Test Loss: 0.06116 | Test RMSE: 0.38775\n",
      "EPOCH: 43\n",
      "Train Loss: 0.06756 | Train RMSE: 0.37223\n",
      "Test Loss: 0.05632 | Test RMSE: 0.39056\n",
      "EPOCH: 44\n",
      "Train Loss: 0.06586 | Train RMSE: 0.36906\n",
      "Test Loss: 0.05615 | Test RMSE: 0.36512\n",
      "EPOCH: 45\n",
      "Train Loss: 0.07410 | Train RMSE: 0.37187\n",
      "Test Loss: 0.05432 | Test RMSE: 0.37574\n",
      "EPOCH: 46\n",
      "Train Loss: 0.07367 | Train RMSE: 0.37840\n",
      "Test Loss: 0.06111 | Test RMSE: 0.39450\n",
      "EPOCH: 47\n",
      "Train Loss: 0.07614 | Train RMSE: 0.37260\n",
      "Test Loss: 0.05555 | Test RMSE: 0.37622\n",
      "EPOCH: 48\n",
      "Train Loss: 0.06366 | Train RMSE: 0.36725\n",
      "Test Loss: 0.05338 | Test RMSE: 0.35891\n",
      "EPOCH: 49\n",
      "Train Loss: 0.05023 | Train RMSE: 0.38656\n",
      "Test Loss: 0.08468 | Test RMSE: 0.42802\n",
      "EPOCH: 50\n",
      "Train Loss: 0.06931 | Train RMSE: 0.37058\n",
      "Test Loss: 0.05611 | Test RMSE: 0.36422\n"
     ]
    }
   ],
   "source": [
    "train(50, train_dl_mass, test_dl_mass, net_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current combination of number of epochs, loss function, and optimizer are what we found to work best.  We encourage users to explore other combinations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# torch.save(net_mass.state_dict(), '../../data/AGNet.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loop outputs plot of results + dataframe of object ID, ground truth values, and network predictions\n",
    "def test(testloader, mdl):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        test_ID, test_pred, test_gt = list(), list(), list()\n",
    "\n",
    "        for data in testloader:\n",
    "            ID, features, ground_truth = data  \n",
    "            test_ID.append(ID.float())\n",
    "            test_gt.append(ground_truth.float())\n",
    "            output_test = mdl(features.float()) \n",
    "            test_pred.append(output_test.float())\n",
    "            test_loss = loss_function(output_test.squeeze(), ground_truth.float())\n",
    "\n",
    "        test_ground_truth = torch.cat(test_gt).data\n",
    "        test_predictions = torch.cat(test_pred).data.flatten()\n",
    "        test_rmse = np.sqrt(metrics.mean_squared_error(test_ground_truth, test_predictions))\n",
    "        ID = torch.cat(test_ID).data\n",
    "\n",
    "        plt.plot(test_ground_truth, test_ground_truth,color='black', label = 'Mass Ground Truth')\n",
    "        plt.scatter(test_ground_truth, test_predictions,s=2, color='blue', label = 'NN prediction')\n",
    "        plt.title('RMSE:' + str(test_rmse) + ' | LOSS: ' + str(test_loss.data.numpy()))\n",
    "        plt.xlabel('AGN Mass')\n",
    "        plt.ylabel('AGN Mass')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        df = pd.DataFrame({'ID':ID.numpy(), 'ground truth':test_ground_truth.numpy(), 'network predictions':test_predictions.numpy() })\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test(test_dl_mass, net_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output test-set results to csv\n",
    "df.to_csv('../../data/AGNet_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
